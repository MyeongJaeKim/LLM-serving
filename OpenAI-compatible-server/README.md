# OpenAI Compatible Server
vLLM 은 SDK 처럼 라이브러리로 프로그램 코드에 로드해서 쓸 수 있는 기능을 제공하고 있는데, 자체 내장 코드로 OpenAI REST API 와 똑같은 인터페이스를 제공하는 자체 서버를 띄울 수 있습니다.

# 전제
vLLM 을 사용하기 위하여 다음과 같은 전제 사항 확인이 필요합니다.
## 버전
* Python : 3.10.x
* CUDA : 12.x
## 모델
### 자체 개발 모델
vLLM 은 지원하는 모델의 종류가 정해져 있으며 버전이 올라갈 때마다 새로 발표된 오픈소스 LLM 들을 추가 지원합니다. 다음 